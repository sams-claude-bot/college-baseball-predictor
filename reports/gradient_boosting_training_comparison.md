# Gradient Boosting Training Data Comparison

**Generated:** 2026-02-17 21:43

## Study Design

Compared XGBoost and LightGBM model performance when trained on different datasets:

| Training Set | Samples | Description |
|--------------|---------|-------------|
| Historical | 4653 | 2024-2025 season games |
| 2026 Only | 67 | Current season (excluding test) |
| Combined | 4888 | Historical + 2026 train |

**Test Set:** 100 games (last ~100 games of 2026 season)

---

## Moneyline Results

| Model | Training Data | Accuracy | Log Loss |
|-------|---------------|----------|----------|
| XGBoost | Combined | 72.0% | 0.5905 |
| LightGBM | Combined | 72.0% | 0.5679 |
| LightGBM | Historical | 70.0% | 0.5842 |
| XGBoost | Historical | 68.0% | 0.6207 |
| XGBoost | 2026 Only | 52.0% | 0.7500 |
| LightGBM | 2026 Only | 49.0% | 0.7499 |

---

## Totals Results

| Model | Training Data | MAE | RMSE |
|-------|---------------|-----|------|
| LightGBM | 2026 Only | 4.501 | 5.970 |
| LightGBM | Combined | 4.658 | 6.197 |
| LightGBM | Historical | 4.675 | 6.237 |
| XGBoost | Historical | 5.143 | 6.853 |
| XGBoost | Combined | 5.236 | 6.808 |
| XGBoost | 2026 Only | 5.782 | 7.482 |

---

## Spread Results

| Model | Training Data | MAE | Run Line Acc |
|-------|---------------|-----|--------------|
| LightGBM | Historical | 5.239 | 17.0% |
| LightGBM | Combined | 5.407 | 19.0% |
| XGBoost | Historical | 5.507 | 17.0% |
| XGBoost | Combined | 5.696 | 15.0% |
| LightGBM | 2026 Only | 5.974 | 17.0% |
| XGBoost | 2026 Only | 6.413 | 14.0% |

---

## Analysis

### Best Performers by Task

**Moneyline:** XGBoost trained on Combined (72.0% accuracy)

**Totals:** LightGBM trained on 2026 Only (4.501 MAE)

**Spread:** LightGBM trained on Historical (5.239 MAE, 17.0% run line)

### Key Findings

1. **LightGBM** slightly outperforms XGBoost (2/3 tasks)

2. **Training Data Impact:**
   - Combined historical + current season data works best
   - More data generally helps gradient boosting models

### Recommendations

1. **Use combined training data** for production models
   - Historical games provide volume for stable feature learning
   - Current season games capture recent team performance
   
2. **Retrain periodically** as more 2026 games are played
   - Weekly retraining recommended during active season
   
3. **Consider ensemble** of XGBoost + LightGBM for robustness

---

*Report generated by `scripts/compare_gb_training.py`*
